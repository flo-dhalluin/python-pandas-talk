{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python + Pandas is love\n",
    "\n",
    "L'idéal pour une rapport de données, la validation d'une intuition, vite fait, sur un coin de table, en mode oneshot / quick&dirty ? ~~Excel~~ [Pandas](https://pandas.pydata.org/) !\n",
    "\n",
    "Nous allons suivre la génération d'un rapport à partir d'un _petit_ dump de données, ce qui va nous permettre de faire une visite guidée des fonctionnalités de pandas. Ce ne sera pas exhaustif, mais devrait vous permettre d'y penser la prochaine fois. \n",
    "\n",
    "[Version page web](https://nbviewer.jupyter.org/github/flo-dhalluin/python-pandas-talk/blob/master/pandas-talk-run.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sortons les outils : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La base : Serie\n",
    "\n",
    "Une série, est une séquence de valeurs, de type homogène (toutes du même type : String, entiers, flotants, dates ... ), __ avec un index __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series([6,5,4,3,2,1], index=10 * np.arange(6)) # index par default : 0, 1 .. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La base : Dataframe\n",
    "\n",
    "Un Dataframe, c'est un tableau : \n",
    "- un ensemble de Series, nommées ( les colonnes)\n",
    "- qui partagent un index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"time\": pd.date_range(\"2018-01-01\", periods=120, freq=\"2H\"),\n",
    "                     \"value\": np.random.random(120),                            \n",
    "                     \"category\": pd.Categorical(list(\"abcdef\" * 20))}) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La base : Import/Export\n",
    "\n",
    "L'idée étant évidemment d'importer nos données ici, et pas de les générer. Pandas supporte à peu près tout les fichiers formats de données courants :\n",
    "- csv \n",
    "- excel \n",
    "- hdf5 \n",
    "- json/msgpack/parquet\n",
    "\n",
    "_mais aussi_  on peut créer un dataframe directement depuis une requête SQL, ou même Big Query.\n",
    "\n",
    "Nous allons ici utiliser la lingua franca de la data ( rappel du contexte : on est sale, on est rapide, on est pas sexys ...) : le csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv(\"events.csv\", \n",
    "                     delimiter=\";\", \n",
    "                     index_col=0,\n",
    "                     parse_dates=True) # auto magie. \n",
    "\n",
    "events.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Une petite vérif rapido :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notons bien que : il n'y a que 4 valeurs possibles pour doc_type et beaucoup de \"non-valeurs\" pour doc_type donc : \n",
    "on nettoye tout ça. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "events.type = events.type.astype(\"category\")\n",
    "events.doc_type = events.doc_type.fillna(\"UNKNOWN\").astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's go\n",
    "\n",
    "### Les données :\n",
    "\n",
    "Les clients remplissent des dossiers pour soucrire à des produits, ils doivent envoyer certains justificatifs qui sont\n",
    "  validés automatiquement (ou pas). events enregistre les différentes soumissions de documents. (client_uuid, correspondant à un dossier). Si la validation automatique (colonne status ) peut échouer : le client resoumet un document du même type.\n",
    "\n",
    "### Le problème\n",
    "Nous voudrions compiler un peu des stats sur le nombre de soumission, par type de document ... ( combien de soumission par dossier / type de document, le timing .. )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Requêtes simples : par index\n",
    "\n",
    "l'opérateur `[]` est contre-intuitif. \n",
    "\n",
    "\n",
    "sinon, pour retrouver des lignes par index :  c'est `.iloc` (index numérique ) ou `.loc` (index déclaré )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "events.iloc[241]  # par index de la ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par l'index déclaré, oh, on peut évidemment utilser la syntax slice de python \n",
    "events.loc['2017-01-10':'2017-01-11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En fait le fonctionnement de `[]` c'est : \n",
    "\n",
    "- selection de colonnes : `events[\"type\"]` \n",
    "- avec une série de boolean : filtre / requêtes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "selected = (events.doc_type == \"CNI\") & (events.index.date == datetime.date(2017, 1, 10))\n",
    "cni_events = events[selected]\n",
    "\n",
    "print(\"%d events recorded on January 10th\" % len(cni_events))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ou encore `query()` qui est parfois plus lisible, et plus puissante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# un peu plus lisible : les CNI avant le 10 janvier, en errer ( status : False)\n",
    "events.query('doc_type==\"CNI\" & index < \"20170110\" & ~status').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GroupBy\n",
    "\n",
    "> Tableau croisé dynamique, c'est mieux si on en reste là.\n",
    "\n",
    "Passons dans le vif du sujet, et moulinons un peu nos datas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# comptons les soumissions de documents par type/status. \n",
    "(events.groupby(('doc_type','status')) # groupage imbriqué : pour chaque doc_type puis le statut \n",
    "       .count())   # fonction d'aggregation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Split - apply/transform - combine\n",
    "\n",
    "Insérons ici _une jolie image_ pour illuster le flux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# utiliseons groupby pour \"numéroter\" les soumissions par utilisateurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "events[\"timestamp\"] = events.index # --- groupby transform pas très heureux avec les index\n",
    "\n",
    "# groupons par dossier, puis chaque document\n",
    "grouped_doc = events.groupby(('client_uuid','doc_type'))\n",
    "\n",
    "# on transforme une colonne. ( Split - apply - combine)\n",
    "events['doc_submission_count'] = grouped_doc[\"timestamp\"].transform(np.argsort)\n",
    "events['time_since_first'] = events.groupby('client_uuid')[\"timestamp\"].transform(lambda ts: ts-ts[0])\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Nb moyen de soumissions de doc avant succés : PAR Type de doc.\n",
    "(events[events.status==True] # seulement les soumissions ok\n",
    "     .groupby('doc_type')    # toujours le petit groupby ... \n",
    "     .doc_submission_count   # quantième soumission\n",
    "     .aggregate(['mean', 'max', 'min'])) # aggregation des stats.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Des graphiques ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# temps passé par dossier\n",
    "\n",
    "(events.groupby('client_uuid') # Tu vois ce que je veux dire ? \n",
    "     .time_since_first # juste le temps depuis la première action\n",
    "     .max().map(lambda x: x.total_seconds()) # timedelta -> \"float\" ( seconds )\n",
    "     .hist(bins=50)) # KABOOM !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encore plus de trucs fun: join et pivot. \n",
    "\n",
    "... To be continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- [sources](https://github.com/flo-dhalluin/python-pandas-talk)\n",
    "- fait avec [jupyter / notebook](https://jupyter.org/)\n",
    "- Le saviez vous ? vous pouvez exporter un notebook en slides/reveal.js\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
