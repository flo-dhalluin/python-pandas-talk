{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python + Pandas is love\n",
    "\n",
    "![Logo Pandas](pics/pandas_logo.png)\n",
    "\n",
    "L'idéal pour une rapport de données, la validation d'une intuition, vite fait, sur un coin de table, en mode oneshot / quick&dirty ? ~~Excel~~ [Pandas](https://pandas.pydata.org/) !\n",
    "\n",
    "Nous allons suivre la génération d'un rapport à partir d'un _petit_ dump de données, ce qui va nous permettre de faire une visite guidée des fonctionnalités de pandas. Ce ne sera pas exhaustif, mais devrait vous permettre d'y penser la prochaine fois. \n",
    "\n",
    "[Version page web](https://nbviewer.jupyter.org/github/flo-dhalluin/python-pandas-talk/blob/master/pandas-talk-run.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sortons les outils : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La base : Serie\n",
    "\n",
    "Une série, est une séquence de valeurs, de type homogène (toutes du même type : String, entiers, flotants, dates ... ), __ avec un index __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series([6,5,4,3,2,1], index=10 * np.arange(6)) # index par default : 0, 1 .. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La base : Dataframe\n",
    "\n",
    "Un Dataframe, c'est un tableau : \n",
    "- un ensemble de Series, nommées ( les colonnes)\n",
    "- qui partagent un index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"time\": pd.date_range(\"2018-01-01\", periods=120, freq=\"2H\"),\n",
    "                     \"value\": np.random.random(120),                            \n",
    "                     \"category\": pd.Categorical(list(\"abcdef\" * 20))}) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La base : Import/Export\n",
    "\n",
    "L'idée étant évidemment d'importer nos données ici, et pas de les générer. Pandas supporte à peu près tout les fichiers formats de données courants :\n",
    "- csv \n",
    "- excel \n",
    "- hdf5 \n",
    "- json/msgpack/parquet\n",
    "\n",
    "_mais aussi_  on peut créer un dataframe directement depuis une requête SQL, ou même Big Query.\n",
    "\n",
    "Nous allons ici utiliser la lingua franca de la data ( rappel du contexte : on est sale, on est rapide, on est pas sexys ...) : le csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv(\"events.csv\", \n",
    "                     delimiter=\";\", \n",
    "                     index_col=0,\n",
    "                     parse_dates=True) # auto magie. \n",
    "events.sort_index(inplace=True)\n",
    "events.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Une petite vérif rapido :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notons bien que : il n'y a que 4 valeurs possibles pour doc_type et beaucoup de \"non-valeurs\" pour doc_type donc : \n",
    "on nettoye tout ça. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "events.type = events.type.astype(\"category\")\n",
    "events.doc_type = events.doc_type.fillna(\"UNKNOWN\").astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Le problème\n",
    "Nous voudrions compiler un peu des stats sur le nombre de soumission, par type de document ... ( combien de soumission par dossier / type de document, le timing .. )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Requêtes simples : par index\n",
    "\n",
    "<font color=\"red\"> Bon gros warning :   l'opérateur `[]` est contre-intuitif. </font>\n",
    "\n",
    "\n",
    "Pour retrouver des lignes par index :  c'est `.iloc` (index numérique ) ou `.loc` (index déclaré )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "events.iloc[241]  # par index de la ligne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On peut évidemment utiliser la syntaxe slice de python : (rappel : l'index est le timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Tous les évenements du 10 janvier\n",
    "events.loc['2017-01-10':'2017-01-11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En fait Il y a 2 cas d'usages pour `[]` \n",
    "\n",
    "selection d'une ou plusieurs colonnes :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[[\"doc_type\", \"status\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ou pour __filtrer__ : avec une série de booléens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Les events concernant des CNI, le 10 janvier\n",
    "(events[ (events.doc_type == \"CNI\") \n",
    "       & (events.index.date == datetime.date(2017, 1, 10)) ]\n",
    "       .head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ou encore `query()` qui est parfois plus lisible, et plus puissante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# un peu plus lisible : les CNI avant le 10 janvier, en errer ( status : False)\n",
    "events.query('doc_type==\"CNI\" & index < \"20170110\" & ~status').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GroupBy\n",
    "\n",
    "> Tableau croisé dynamique, c'est mieux si on en reste là.\n",
    "\n",
    "Passons dans le vif du sujet, et moulinons un peu nos datas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# comptons les soumissions de documents par type/status. \n",
    "\n",
    "(events.groupby(('doc_type','status'))\n",
    "       .count()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![groupby](./pics/scan_groupby.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "events[\"timestamp\"] = events.index # je crée une colonne ( l'index est perdu dans un groupby )\n",
    "\n",
    "# Comme on créé une nouvelle colonne\n",
    "events[\"submission_idx\"] = (events.groupby((\"client_uuid\", \"doc_type\"))\n",
    "                                  [\"timestamp\"]  # uniquement sur la colonne \"timestamp\" \n",
    "                                  .transform(np.argsort))\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cette fois ci, je veux calculer le temps passé par utilisateur _depuis le premier évenement lié à cet utilisateur_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "events['time_since_first'] = (events.groupby('client_uuid')\n",
    "                              [\"timestamp\"]\n",
    "                              .transform(lambda ts: ts-ts[0])) # C'est là !\n",
    "\n",
    "events.sort_values(by=[\"client_uuid\", \"timestamp\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "statistiques du nombre de soumissions par type de doc (et après on arrête... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(events.groupby((\"doc_type\", \"submission_idx\"))\n",
    "                .time_since_first\n",
    "                .aggregate({\"counts\": \"count\",\n",
    "                            \"mean_time\": lambda g: g.mean()})) # \"mean\" string shortcut does not work on timedeltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pivot \n",
    "\n",
    "En fait, il y a un autre moyen de faire le dernier calcul, comme s'intéresse uniquement au nombre total de soumissions par type de documents : `.pivot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_counts = pd.pivot_table(events, \n",
    "                   index=\"client_uuid\", # une ligne par client_uuid. ok\n",
    "                   columns=\"doc_type\", # une colonne par type de doc\n",
    "                   values=\"timestamp\", # du coup : on a un timestamp par soumission\n",
    "                   aggfunc=\"count\")    # qu'on compte.\n",
    "\n",
    "submission_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "submission_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Des graphiques ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# temps passé par dossier\n",
    "\n",
    "(events.groupby('client_uuid') # Tu vois ce que je veux dire ? \n",
    "     .time_since_first # juste le temps depuis la première action\n",
    "     .max().map(lambda x: x.total_seconds()) # timedelta -> \"float\" ( seconds )\n",
    "     .hist(bins=50)) # KABOOM !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Et maintenant ? \n",
    "\n",
    "Vous avez la base, vous pouvez plonger plus loin : \n",
    "- `.merge` et `.join` : si j'ai 2 tables, des jointures comme à la maison ! \n",
    "- les timeseries, et tout ce qu'on peut faire avec ( resampling, rolling windows, conversions .. )\n",
    "\n",
    "Et une fois que vous avez bien tout nettoyé, évidement, on peut jouer avec scikit-learn pour faire du Machine learning, ou [bokeh](https://bokeh.pydata.org/) pour des zouli graphiques, direct depuis pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Merci ! \n",
    "\n",
    "- [sources](https://github.com/flo-dhalluin/python-pandas-talk)\n",
    "- fait avec [jupyter / notebook](https://jupyter.org/)\n",
    "- Le saviez vous ? vous pouvez exporter un notebook en slides/reveal.js\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
