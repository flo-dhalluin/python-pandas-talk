{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python + Pandas is love\n",
    "\n",
    "L'idéal pour une rapport de données, la validation d'une intuition, vite fait, sur un coin de table, en mode oneshot / quick&dirty ? ~~Excel~~ [Pandas](https://pandas.pydata.org/) !\n",
    "\n",
    "Nous allons suivre la génération d'un rapport à partir d'un _petit_ dump de données, ce qui va nous permettre de faire une visite guidée des fonctionnalités de pandas. Ce ne sera pas exhaustif, mais devrait vous permettre d'y penser la prochaine fois. \n",
    "\n",
    "(Version page web)[https://nbviewer.jupyter.org/github/flo-dhalluin/python-pandas-talk/blob/master/pandas-talk-run.ipynb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Serie\n",
    "\n",
    "Une série, est une séquence de valeurs, de type homogène (toutes du même type : String, entiers, flotants, dates ... ), __ avec un index __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series([5,4,3,2,1,2,3,4,5])\n",
    "s_datetimes = pd.date_range(start=\"2017-01-01\", periods=86400, freq=\"2H\").to_series()\n",
    "\n",
    "#display(s.head())\n",
    "s_datetimes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataframe\n",
    "\n",
    "Un Dataframe, c'est un tableau : \n",
    "- un ensemble de Series, nommées ( les colonnes)\n",
    "- qui partagent un index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"time\": s_datetimes[:120].values,  # get rid of the index\n",
    "                     \"value\": np.random.random(120),\n",
    "                     \"category\": pd.Categorical(list(\"abcdef\" * 20))})\n",
    "\n",
    "print(data.info(()))\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Import/Export\n",
    "\n",
    "L'idée étant évidemment d'importer nos données ici, et pas de les générer. Pandas supporte à peu près tout les fichiers formats de données courants :\n",
    "- csv \n",
    "- excel \n",
    "- hdf5 \n",
    "- json/msgpack/parquet\n",
    "\n",
    "_mais aussi_  on peut créer un dataframe directement depuis une requête SQL, ou même Big Query.\n",
    "\n",
    "Nous allons ici utiliser la lingua franca de la data ( rappel du contexte : on est sale, on est rapide, on est pas sexys ...) : le csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clients = pd.read_csv(\"client_files.csv\", delimiter=\";\", index_col=0, parse_dates=[1])\n",
    "#display(clients.head(4))\n",
    "events = pd.read_csv(\"events.csv\", delimiter=\";\", index_col=0, parse_dates=True)\n",
    "#display(events.info())\n",
    "print(\"events is row x cols\", events.shape)\n",
    "print(\"columns are : \", events.columns)\n",
    "print(\"time range:\", events.index.min(), events.index.max())\n",
    "display(events.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's go\n",
    "\n",
    "### Les données :\n",
    "\n",
    "Les clients remplissent des dossiers pour soucrire à des produits, ils doivent envoyer certains justificatifs qui sont\n",
    "  validés automatiquement (ou pas). events enregistre les différentes soumissions de documents. (client_uuid, correspond à un dossier). comme la validation automatique peut échouer, le client resoumet ces pièces.\n",
    "\n",
    "### Le problème\n",
    "Nous voudrions compiler un peu des stats sur le nombre de soumission, par type de dossier ... juste à partir de la table des evenements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Requêtes simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "cni_events = events[events.doc_type == \"CNI\"] # keep only CNI type docs\n",
    "# keep only events occuring on january 10th. \n",
    "day_events = events[events.index.date == datetime.date(2017,1,10)]\n",
    "\n",
    "print(\"%d events recorded on January 10th\" % len(day_events))\n",
    "\n",
    "# By Index : .ix  - by \"position\" .iloc \n",
    "events.iloc[14:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Pour des requêtes encore plus péchues \n",
    "\n",
    "events.query('doc_type==\"RIB\" & status & index > \"20170110\"').head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GroupBy\n",
    "\n",
    "> Tableau croisé dynamique, c'est mieux si on en reste là...\n",
    "\n",
    "Passons dans le vif du sujet, et moulinons un peu nos data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# comptons les soumissions de documents par type/status. \n",
    "(events.groupby(('doc_type','status')) # groupage imbriqué \n",
    "       .count())   # fonction d'aggregation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Split - apply/transform - combine\n",
    "\n",
    "Insérons ici _une jolie image_ pour illuster le flux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# utiliseons groupby pour \"numéroter\" les soumissions par utilisateurs\n",
    "\n",
    "# cleanup\n",
    "events['doc_type'] = events['doc_type'].fillna('NO_DOC')\n",
    "events[\"timestamp\"] = events.index # --- groupby transform pas très heureux avec les index\n",
    "\n",
    "# groupons par dossier, puis chaque document\n",
    "grouped_doc = events.groupby(('client_uuid','doc_type'))\n",
    "\n",
    "# on transforme une colonne. ( Split - apply - combine)\n",
    "events['doc_submission_count'] = grouped_doc[\"timestamp\"].transform(np.argsort)\n",
    "events['time_since_first'] = events.groupby('client_uuid')[\"timestamp\"].transform(lambda ts: ts-ts[0])\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Nb moyen de soumissions de doc avant succés : PAR Type de doc.\n",
    "(events[events.status==True] # seulement les soumissions ok\n",
    "     .groupby('doc_type')    # toujours le petit groupby ... \n",
    "     .doc_submission_count   # quantième soumission\n",
    "     .aggregate(['mean', 'max', 'min'])) # aggregation des stats.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Des graphiques ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# temps passé par dossier\n",
    "\n",
    "(events.groupby('client_uuid') # Tu vois ce que je veux dire ? \n",
    "     .time_since_first # juste le temps depuis la première action\n",
    "     .max().map(lambda x: x.total_seconds()) # timedelta -> \"float\" ( seconds )\n",
    "     .hist(bins=50)) # KABOOM !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encore plus de trucs fun: join et pivot. \n",
    "\n",
    "... To be continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- [sources](https://github.com/flo-dhalluin/python-pandas-talk)\n",
    "- fait avec [jupyter / notebook](https://jupyter.org/)\n",
    "- Le saviez vous ? vous pouvez exporter un notebook en slides/reveal.js\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
