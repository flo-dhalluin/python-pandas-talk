{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python + Pandas is love\n",
    "\n",
    "![Logo Pandas](pics/pandas_logo.png)\n",
    "\n",
    "~~Excel~~ [Pandas](https://pandas.pydata.org/) !\n",
    "\n",
    "<img src=\"pics/logo_sunny.svg\" width=\"33%\" style=\"display:block; margin-left:auto; margin-right:auto\">\n",
    "\n",
    "[Version page web](https://nbviewer.jupyter.org/github/flo-dhalluin/python-pandas-talk/blob/master/pandas-talk-run.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Le cas d'usage simple : \n",
    "\n",
    "- Valider une intuition\n",
    "- un rapport simple à partir de données brutes\n",
    "- un petit script oneshot vite fait \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sortons les outils : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La base : Serie\n",
    "\n",
    "Une série, est une séquence de valeurs, de type homogène (toutes du même type : String, entiers, flotants, dates ... ), __ avec un index __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series([6,5,4,3,2,1], index=10 * np.arange(6)) # index par default : 0, 1 .. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La base : Dataframe\n",
    "\n",
    "Un Dataframe, c'est un tableau : \n",
    "- un ensemble de Series, nommées ( les colonnes)\n",
    "- qui partagent un index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"time\": pd.date_range(\"2018-01-01\", periods=120, freq=\"2H\"),\n",
    "                     \"value\": np.random.random(120),                            \n",
    "                     \"category\": pd.Categorical(list(\"abcdef\" * 20))}) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La base : Import/Export\n",
    "\n",
    "L'idée étant évidemment d'importer nos données ici, et pas de les générer. Pandas supporte à peu près tout les fichiers formats de données courants :\n",
    "- csv \n",
    "- excel \n",
    "- hdf5 \n",
    "- json/msgpack/parquet\n",
    "\n",
    "_mais aussi_  on peut créer un dataframe directement depuis une requête SQL, ou même Big Query.\n",
    "\n",
    "Nous allons ici utiliser la lingua franca de la data ... LE CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv(\"events.csv\", \n",
    "                     delimiter=\";\", \n",
    "                     index_col=0,\n",
    "                     parse_dates=True) # auto magie. \n",
    "events.sort_index(inplace=True)\n",
    "events.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Une petite vérif rapido :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 valeurs possibles pour doc_type et beaucoup de \"non-valeurs\" pour doc_type donc : \n",
    "on nettoye tout ça. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "events.type = events.type.astype(\"category\")\n",
    "events.doc_type = events.doc_type.fillna(\"UNKNOWN\").astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Le problème\n",
    "Nous voudrions compiler un peu des stats sur le nombre de soumission, par type de document ... ( combien de soumission par dossier / type de document, le timing .. )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Requêtes simples : par index\n",
    "\n",
    "<font color=\"red\"> Bon gros warning :   l'opérateur `[]` est contre-intuitif. </font>\n",
    "\n",
    "\n",
    "Pour retrouver des lignes par index :  c'est `.iloc` (index numérique ) ou `.loc` (index déclaré )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "events.iloc[241]  # par index de la ligne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "avec la syntaxe slice de python : (rappel : l'index est le timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Tous les évenements du 10 janvier au 11 janvier (exclus)\n",
    "events.loc['2017-01-10':'2017-01-11'].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En fait Il y a 2 cas d'usages pour `[]` \n",
    "\n",
    "selection d'une ou plusieurs colonnes :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[[\"doc_type\", \"status\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ou pour __filtrer__ : avec une série de booléens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Les events concernant des CNI, le 10 janvier\n",
    "(events[ (events.doc_type == \"CNI\") \n",
    "       & (events.index.date == datetime.date(2017, 1, 10)) ]\n",
    "       .head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ou encore `query()` qui est parfois plus lisible, et plus puissante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# un peu plus lisible : les CNI avant le 10 janvier,\n",
    "# en erreur ( status : False)\n",
    "(events.query('doc_type==\"CNI\" & index < \"20170110\" & ~status')\n",
    "      .head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GroupBy\n",
    "\n",
    "> Tableau croisé dynamique, c'est mieux si on en reste là.\n",
    "\n",
    "Passons dans le vif du sujet, et moulinons un peu nos datas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![groupby](./pics/groupby.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "events[\"timestamp\"] = events.index # je crée une colonne ( l'index est perdu dans un groupby )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "events[\"submission_idx\"] = (events.groupby((\"client_uuid\", \"doc_type\"))\n",
    "                                  [\"timestamp\"]\n",
    "                                  .transform(np.argsort))\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cette fois ci, je veux calculer le temps passé par utilisateur _depuis le premier évenement lié à cet utilisateur_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "events['time_since_first'] = (events.groupby('client_uuid')\n",
    "                              [\"timestamp\"]\n",
    "                              .transform(lambda ts: ts-ts[0])) # C'est là !\n",
    "\n",
    "events.sort_values(by=[\"client_uuid\", \"timestamp\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "statistiques du nombre de soumissions par type de doc (et après on arrête... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(events.groupby((\"doc_type\", \"submission_idx\"))\n",
    "                .time_since_first\n",
    "                .aggregate([(\"counts\", \"count\"),\n",
    "                            (\"mean_time\", lambda g: g.mean())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "![groupby](./pics/pivot.svg.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "submission_counts = pd.pivot_table(events, \n",
    "                   index=\"client_uuid\",\n",
    "                   columns=\"doc_type\",\n",
    "                   values=\"timestamp\",\n",
    "                   aggfunc=\"count\")\n",
    "\n",
    "submission_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "submission_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Des graphiques ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# temps passé par dossier\n",
    "\n",
    "(events.groupby('client_uuid')\n",
    "     .time_since_first # juste le temps depuis la première action\n",
    "     .max() # l'évenement le plus long... \n",
    "     .map(lambda x: x.total_seconds())\n",
    "     .hist(bins=50)) # KABOOM !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "(events.loc[\"20170110\"] \n",
    "        .resample('H') # H - aggregation par heure\n",
    "        .doc_type\n",
    "        .count().plot(title=\"nombre d'évenements par heure\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Et maintenant ? \n",
    "\n",
    "Vous avez la base, vous pouvez plonger plus loin : \n",
    "- `.merge` et `.join` : si j'ai 2 tables, des jointures comme à la maison ! \n",
    "- les timeseries, et tout ce qu'on peut faire avec ( resampling, rolling windows, conversions .. )\n",
    "\n",
    "Et une fois que vous avez bien tout nettoyé, évidement, on peut jouer avec scikit-learn pour faire du Machine learning, ou [bokeh](https://bokeh.pydata.org/) pour des zouli graphiques, direct depuis pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Merci ! \n",
    "\n",
    "- Cette présentation est un notebook dispo sur github :\n",
    "    [https://github.com/flo-dhalluin/python-pandas-talk](https://github.com/flo-dhalluin/python-pandas-talk)\n",
    "- fait avec [jupyter / notebook](https://jupyter.org/)\n",
    "\n",
    "\n",
    " <img src=\"pics/twitter.png\" width=\"50px\" style=\"display:inline\"/>  [@flal](https://twitter.com/flal)\n",
    " \n",
    " [Netheos recrute !](https://www.netheos.com), venez m'en parler ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Join (ou pluôt ... merge )\n",
    "\n",
    "Des jointures, comme à la maison ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clients = pd.read_csv(\"client_files.csv\", delimiter=\";\", index_col=0)\n",
    "clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(events, clients, \n",
    "                 left_on=\"client_uuid\", \n",
    "                 right_index=True, \n",
    "                 how=\"left\") # ou bien inner, outer .\n",
    "# equivalent à \n",
    "# events.join(clients, on=\"client_uuid\")\n",
    "display(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# on va pouvoir faire des stats par produits !\n",
    "# nombre de resoumissions pour le RIB, par produit\n",
    "\n",
    "(clients.join(submission_counts)\n",
    "     .groupby(\"product\")\n",
    "     .RIB # on regarde les RIB\n",
    "     .value_counts().unstack()\n",
    "     .plot.bar())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
